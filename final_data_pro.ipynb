{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50193b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "# ---------------------------\n",
    "# 0) change the image path\n",
    "# ---------------------------\n",
    "ROOT_DIR   = r\"D:\\bishe\\CUB_200_2011\\CUB_200_2011\"   # CUB \n",
    "OUT_DIR    = r\"D:\\bishe\\data_nor_14_w3_64\"       # output\n",
    "SAM_CKPT   = r\"D:\\bishe\\sam\\sam_vit_b_01ec64.pth\"    # SAM\n",
    "MODEL_TYPE = \"vit_b\"\n",
    "DEVICE     = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "OUTPUT_SIZE = (64, 64)\n",
    "\n",
    "# ---------------------------\n",
    "# 1) read CUB\n",
    "# ---------------------------\n",
    "def load_image_list(root_dir):\n",
    "    p = os.path.join(root_dir, 'images.txt')\n",
    "    ids, relpaths = [], []\n",
    "    with open(p, 'r') as f:\n",
    "        for line in f:\n",
    "            idx, rel = line.strip().split()\n",
    "            ids.append(int(idx))\n",
    "            relpaths.append(rel)\n",
    "    return ids, relpaths\n",
    "\n",
    "def load_keypoints(root_dir):\n",
    "    \"\"\"\n",
    "    return dict: img_id -> {part_id(1..15): (x,y,vis)}\n",
    "    \"\"\"\n",
    "    kp_dict = {}\n",
    "    p = os.path.join(root_dir, 'parts', 'part_locs.txt')\n",
    "    with open(p, 'r') as f:\n",
    "        for line in f:\n",
    "            img_id, part_id, x, y, v = line.strip().split()\n",
    "            img_id  = int(img_id); part_id = int(part_id)\n",
    "            x = float(x); y = float(y); v = int(v)\n",
    "            kp_dict.setdefault(img_id, {})[part_id] = (x, y, v)\n",
    "    return kp_dict\n",
    "\n",
    "def load_bboxes(root_dir):\n",
    "    \"\"\"\n",
    "    return dict: img_id -> (x, y, w, h)\n",
    "    \"\"\"\n",
    "    bbox_dict = {}\n",
    "    p = os.path.join(root_dir, 'bounding_boxes.txt')\n",
    "    with open(p, 'r') as f:\n",
    "        for line in f:\n",
    "            img_id, x, y, w, h = line.strip().split()\n",
    "            bbox_dict[int(img_id)] = (float(x), float(y), float(w), float(h))\n",
    "    return bbox_dict\n",
    "\n",
    "# ---------------------------\n",
    "# 2) SAM \n",
    "# ---------------------------\n",
    "def build_sam(ckpt, model_type=\"vit_b\", device=\"cpu\"):\n",
    "    sam = sam_model_registry[model_type](checkpoint=ckpt).to(device)\n",
    "    predictor = SamPredictor(sam)\n",
    "    return predictor\n",
    "\n",
    "def predict_mask_with_sam(predictor: SamPredictor, image_pil: Image.Image, bbox):\n",
    "    \"\"\"\n",
    "    bbox: (x, y, w, h) in original image coordinates\n",
    "    return: mask (H, W) uint8 in {0,1}\n",
    "    \"\"\"\n",
    "    image_np = np.array(image_pil)\n",
    "    predictor.set_image(image_np)\n",
    "    x, y, w, h = bbox\n",
    "    input_box = np.array([[x, y, x + w, y + h]])\n",
    "    masks, _, _ = predictor.predict(\n",
    "        point_coords=None, point_labels=None,\n",
    "        box=input_box, multimask_output=False\n",
    "    )\n",
    "    return masks[0].astype(np.uint8)\n",
    "\n",
    "# ---------------------------\n",
    "# 3) crop and resize\n",
    "# ---------------------------\n",
    "def crop_and_resize_by_mask(image_pil, mask01, keypoints_xyv, out_wh=(256,256)):\n",
    "    mask_bool = mask01.astype(bool)\n",
    "    if mask_bool.sum() == 0:\n",
    "        w, h = image_pil.size\n",
    "        x_min, y_min, x_max, y_max = 0, 0, w-1, h-1\n",
    "    else:\n",
    "        ys, xs = np.where(mask_bool)\n",
    "        y_min, y_max = ys.min(), ys.max()\n",
    "        x_min, x_max = xs.min(), xs.max()\n",
    "\n",
    "    # \n",
    "    cropped_img = image_pil.crop((x_min, y_min, x_max+1, y_max+1))\n",
    "    cropped_mask = mask01[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "    # \n",
    "    out_w, out_h = out_wh\n",
    "    cw, ch = cropped_img.size\n",
    "    sx, sy = out_w / cw, out_h / ch\n",
    "\n",
    "    # \n",
    "    resized_img = cropped_img.resize((out_w, out_h), Image.BILINEAR)\n",
    "    resized_mask = Image.fromarray((cropped_mask * 255).astype(np.uint8)).resize((out_w, out_h), Image.NEAREST)\n",
    "\n",
    "    # \n",
    "    new_kps = keypoints_xyv.copy().astype(np.float32)\n",
    "    for i, (x, y, v) in enumerate(new_kps):\n",
    "        if v == 0:\n",
    "            continue\n",
    "        nx = (x - x_min) * sx\n",
    "        ny = (y - y_min) * sy\n",
    "        if nx < 0 or nx >= out_w or ny < 0 or ny >= out_h:\n",
    "            new_kps[i, 2] = 0\n",
    "        else:\n",
    "            new_kps[i, 0] = nx\n",
    "            new_kps[i, 1] = ny\n",
    "    return resized_img, resized_mask, new_kps\n",
    "\n",
    "def normalize_keypoints_xy(keypoints_xyv, out_wh=(256,256)):\n",
    "    out_w, out_h = out_wh\n",
    "    k = keypoints_xyv.copy().astype(np.float32)\n",
    "    k[:,0] /= out_w\n",
    "    k[:,1] /= out_h\n",
    "    return k\n",
    "\n",
    "# ---------------------------\n",
    "# 4) CUB15 → 14\n",
    "\n",
    "CUB_TO_AVIAN_PART_IDS = [1, 2, 5, 6, 7, 11, 10, 15, 4, 14, 8, 12, 9, 13]\n",
    "\n",
    "CUB_IDX_0_BASE = [pid-1 for pid in CUB_TO_AVIAN_PART_IDS]\n",
    "\n",
    "def cub15_to_avian14(kpts15_xyv):\n",
    "    \"\"\"\n",
    "    kpts15_xyv: (15,3) in (x,y,v) \n",
    "    return kpts14_xyv: (14,3)\n",
    "    \"\"\"\n",
    "    k14 = kpts15_xyv[CUB_IDX_0_BASE, :]  # 直接索引抽取并重排\n",
    "    return k14\n",
    "\n",
    "# ---------------------------\n",
    "# 5) main\n",
    "# ---------------------------\n",
    "def run(\n",
    "    root_dir=ROOT_DIR,\n",
    "    out_dir=OUT_DIR,\n",
    "    sam_ckpt=SAM_CKPT,\n",
    "    model_type=MODEL_TYPE,\n",
    "    device=DEVICE,\n",
    "    out_size=OUTPUT_SIZE\n",
    "):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    # read\n",
    "    img_ids, img_relpaths = load_image_list(root_dir)\n",
    "    kp_dict = load_keypoints(root_dir)\n",
    "    bbox_dict = load_bboxes(root_dir)\n",
    "\n",
    "    # SAM\n",
    "    predictor = build_sam(sam_ckpt, model_type=model_type, device=device)\n",
    "\n",
    "    for img_id, rel in tqdm(zip(img_ids, img_relpaths), total=len(img_ids)):\n",
    "        img_path = os.path.join(root_dir, 'images', rel)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        k15 = np.zeros((15,3), dtype=np.float32)\n",
    "        parts = kp_dict.get(img_id, {})\n",
    "        for pid in range(1,16):\n",
    "            if pid in parts:\n",
    "                x,y,v = parts[pid]\n",
    "                k15[pid-1] = (x,y,v)  \n",
    "\n",
    "        # bbox\n",
    "        bbox = bbox_dict[img_id]  # (x,y,w,h)\n",
    "\n",
    "        # SAM \n",
    "        mask01 = predict_mask_with_sam(predictor, image, bbox)  # (H,W) 0/1\n",
    "\n",
    "        # \n",
    "        img_resized, mask_resized, k15_cropped = crop_and_resize_by_mask(\n",
    "            image, mask01, k15, out_wh=out_size\n",
    "        )\n",
    "\n",
    "        # \n",
    "        k14 = cub15_to_avian14(k15_cropped)\n",
    "\n",
    "        # （[0,1]）\n",
    "        k14_norm = normalize_keypoints_xy(k14, out_wh=out_size)\n",
    "\n",
    "        # save\n",
    "        sample_id = f\"{img_id:06d}\"\n",
    "        dst = os.path.join(out_dir, sample_id)\n",
    "        os.makedirs(dst, exist_ok=True)\n",
    "\n",
    "        img_resized.save(os.path.join(dst, \"image.png\"))\n",
    "        mask_resized.save(os.path.join(dst, \"mask.png\"))\n",
    "        np.save(os.path.join(dst, \"keypoints_15.npy\"), k15_cropped)   \n",
    "        np.save(os.path.join(dst, \"keypoints14.npy\"), k14)\n",
    "        np.save(os.path.join(dst, \"keypoints14_norm.npy\"), k14_norm)\n",
    "\n",
    "    print(\"✅ finish：image.png, mask.png, keypoints_15.npy, keypoints14.npy, keypoints14_norm.npy\")\n",
    "\n",
    "#run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac1d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
